{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7832676,"sourceType":"datasetVersion","datasetId":4590674}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lesson 3: Sentence Window Retrieval","metadata":{}},{"cell_type":"markdown","source":"![In Sentence-window retrieval.png](https://github.com/YanSte/NLP-RAG-LLamaIndex-Sentence-Window-Retrieval/imgs/shema1.png)\n\n![In Sentence-window retrieval.png](https://github.com/YanSte/NLP-RAG-LLamaIndex-Sentence-Window-Retrieval/imgs/shema.png)","metadata":{}},{"cell_type":"code","source":"import warnings\nfrom kaggle_secrets import UserSecretsClient\nwarnings.filterwarnings('ignore')\n\nuser_secrets = UserSecretsClient()\nOPENAI_API_KEY = user_secrets.get_secret(\"OPEN_AI\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:02:02.641726Z","iopub.execute_input":"2024-03-13T18:02:02.642140Z","iopub.status.idle":"2024-03-13T18:02:02.986481Z","shell.execute_reply.started":"2024-03-13T18:02:02.642109Z","shell.execute_reply":"2024-03-13T18:02:02.985308Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install trulens-eval\n!pip install llama-index\n!pip install llama-index-embeddings-huggingface\n!pip install torch sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:02:03.035394Z","iopub.execute_input":"2024-03-13T18:02:03.035782Z","iopub.status.idle":"2024-03-13T18:03:46.792764Z","shell.execute_reply.started":"2024-03-13T18:02:03.035752Z","shell.execute_reply":"2024-03-13T18:03:46.791032Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport numpy as np\n\nfrom llama_index.core import Document\nfrom llama_index.core import SimpleDirectoryReader\nfrom llama_index.core.query_engine import RetrieverQueryEngine\nfrom llama_index.core.node_parser import HierarchicalNodeParser\nfrom llama_index.core.node_parser import get_leaf_nodes\nfrom llama_index.core import StorageContext\nfrom llama_index.core.retrievers import AutoMergingRetriever\nfrom llama_index.core.indices.postprocessor import SentenceTransformerRerank\nfrom llama_index.core import  load_index_from_storage\nfrom llama_index.core import ServiceContext, VectorStoreIndex, StorageContext\nfrom llama_index.core.node_parser import SentenceWindowNodeParser\nfrom llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor\nfrom llama_index.core.indices.postprocessor import SentenceTransformerRerank\nfrom llama_index.core import load_index_from_storage\nfrom llama_index.core.node_parser import SentenceWindowNodeParser\nfrom trulens_eval.feedback import Groundedness\nfrom llama_index.core.schema import NodeWithScore\nfrom copy import deepcopy\nfrom llama_index.core.indices.postprocessor import SentenceTransformerRerank\nfrom llama_index.core import QueryBundle\nfrom llama_index.core.schema import TextNode, NodeWithScore\nfrom llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor\nfrom llama_index.core.response.notebook_utils import display_response\n\nfrom trulens_eval import (\n    Feedback,\n    TruLlama,\n    OpenAI\n)\nfrom llama_index.llms.openai import OpenAI\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:08:29.503277Z","iopub.execute_input":"2024-03-13T18:08:29.503736Z","iopub.status.idle":"2024-03-13T18:08:29.516313Z","shell.execute_reply.started":"2024-03-13T18:08:29.503702Z","shell.execute_reply":"2024-03-13T18:08:29.515215Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def get_openai_api_key():\n    return OPENAI_API_KEY\n\ndef get_prebuilt_trulens_recorder(query_engine, app_id):\n    from trulens_eval import (\n        Feedback,\n        TruLlama,\n        OpenAI\n    )\n    openai = OpenAI()\n\n    qa_relevance = (\n        Feedback(openai.relevance_with_cot_reasons, name=\"Answer Relevance\")\n        .on_input_output()\n    )\n\n    qs_relevance = (\n        Feedback(openai.relevance_with_cot_reasons, name = \"Context Relevance\")\n        .on_input()\n        .on(TruLlama.select_source_nodes().node.text)\n        .aggregate(np.mean)\n    )\n\n    grounded = Groundedness(groundedness_provider=openai)\n\n    groundedness = (\n        Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n            .on(TruLlama.select_source_nodes().node.text)\n            .on_output()\n            .aggregate(grounded.grounded_statements_aggregator)\n    )\n\n    feedbacks = [qa_relevance, qs_relevance, groundedness]\n    tru_recorder = TruLlama(\n        query_engine,\n        app_id=app_id,\n        feedbacks=feedbacks\n    )\n    return tru_recorder\n\ndef build_automerging_index(\n    documents,\n    llm,\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    save_dir=\"merging_index\",\n    chunk_sizes=None,\n):\n    chunk_sizes = chunk_sizes or [2048, 512, 128]\n    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n    nodes = node_parser.get_nodes_from_documents(documents)\n    leaf_nodes = get_leaf_nodes(nodes)\n    merging_context = ServiceContext.from_defaults(\n        llm=llm,\n        embed_model=embed_model,\n    )\n    storage_context = StorageContext.from_defaults()\n    storage_context.docstore.add_documents(nodes)\n\n    if not os.path.exists(save_dir):\n        automerging_index = VectorStoreIndex(\n            leaf_nodes, storage_context=storage_context, service_context=merging_context\n        )\n        automerging_index.storage_context.persist(persist_dir=save_dir)\n    else:\n        automerging_index = load_index_from_storage(\n            StorageContext.from_defaults(persist_dir=save_dir),\n            service_context=merging_context,\n        )\n    return automerging_index\n\n\ndef get_automerging_query_engine(\n    automerging_index,\n    similarity_top_k=12,\n    rerank_top_n=6,\n):\n    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n    retriever = AutoMergingRetriever(\n        base_retriever, automerging_index.storage_context, verbose=True\n    )\n    rerank = SentenceTransformerRerank(\n        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n    )\n    auto_merging_engine = RetrieverQueryEngine.from_args(\n        retriever, node_postprocessors=[rerank]\n    )\n    return auto_merging_engine\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:16:10.543862Z","iopub.execute_input":"2024-03-13T18:16:10.544255Z","iopub.status.idle":"2024-03-13T18:16:10.560862Z","shell.execute_reply.started":"2024-03-13T18:16:10.544223Z","shell.execute_reply":"2024-03-13T18:16:10.559495Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"openai.api_key = get_openai_api_key()\nos.environ[\"OPENAI_API_KEY\"] = get_openai_api_key()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:18:12.472555Z","iopub.execute_input":"2024-03-13T18:18:12.473003Z","iopub.status.idle":"2024-03-13T18:18:12.478520Z","shell.execute_reply.started":"2024-03-13T18:18:12.472967Z","shell.execute_reply":"2024-03-13T18:18:12.477501Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"documents = SimpleDirectoryReader(\n    input_files=[\"/kaggle/input/data-test/eBook-How-to-Build-a-Career-in-AI.pdf\"]\n).load_data()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:04:04.843031Z","iopub.execute_input":"2024-03-13T18:04:04.843906Z","iopub.status.idle":"2024-03-13T18:04:06.684491Z","shell.execute_reply.started":"2024-03-13T18:04:04.843859Z","shell.execute_reply":"2024-03-13T18:04:06.683525Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(type(documents), \"\\n\")\nprint(len(documents), \"\\n\")\nprint(type(documents[0]))\nprint(documents[0])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:04:06.686171Z","iopub.execute_input":"2024-03-13T18:04:06.686892Z","iopub.status.idle":"2024-03-13T18:04:06.693816Z","shell.execute_reply.started":"2024-03-13T18:04:06.686852Z","shell.execute_reply":"2024-03-13T18:04:06.692593Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<class 'list'> \n\n41 \n\n<class 'llama_index.core.schema.Document'>\nDoc ID: 072787c0-c75c-427b-9690-6d282e4ba0b7\nText: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\nHow to  Build Your Career in AIA Simple Guide\n","output_type":"stream"}]},{"cell_type":"code","source":"document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:05:19.627164Z","iopub.execute_input":"2024-03-13T18:05:19.627536Z","iopub.status.idle":"2024-03-13T18:05:19.634264Z","shell.execute_reply.started":"2024-03-13T18:05:19.627510Z","shell.execute_reply":"2024-03-13T18:05:19.633073Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Window-sentence retrieval setup","metadata":{}},{"cell_type":"markdown","source":"Splits a document into Nodes, with each node being a sentence. Each node contains a window from the surrounding sentences in the metadata.","metadata":{}},{"cell_type":"code","source":"# create the sentence window node parser w/ default settings\nnode_parser = SentenceWindowNodeParser.from_defaults(\n    window_size=3,\n    window_metadata_key=\"window\",\n    original_text_metadata_key=\"original_text\",\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:05:39.785300Z","iopub.execute_input":"2024-03-13T18:05:39.786341Z","iopub.status.idle":"2024-03-13T18:05:39.792168Z","shell.execute_reply.started":"2024-03-13T18:05:39.786306Z","shell.execute_reply":"2024-03-13T18:05:39.790806Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"text = \"hello. how are you? I am fine!  \"\n\nnodes = node_parser.get_nodes_from_documents([Document(text=text)])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:05:40.370917Z","iopub.execute_input":"2024-03-13T18:05:40.371385Z","iopub.status.idle":"2024-03-13T18:05:40.380225Z","shell.execute_reply.started":"2024-03-13T18:05:40.371349Z","shell.execute_reply":"2024-03-13T18:05:40.379064Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print([x.text for x in nodes])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:05:41.601320Z","iopub.execute_input":"2024-03-13T18:05:41.601736Z","iopub.status.idle":"2024-03-13T18:05:41.607131Z","shell.execute_reply.started":"2024-03-13T18:05:41.601701Z","shell.execute_reply":"2024-03-13T18:05:41.605899Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"['hello. ', 'how are you? ', 'I am fine!  ']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(nodes[1].metadata[\"window\"])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:05:42.004656Z","iopub.execute_input":"2024-03-13T18:05:42.005073Z","iopub.status.idle":"2024-03-13T18:05:42.011302Z","shell.execute_reply.started":"2024-03-13T18:05:42.005042Z","shell.execute_reply":"2024-03-13T18:05:42.009715Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"hello.  how are you?  I am fine!  \n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"hello. foo bar. cat dog. mouse\"\n\nnodes = node_parser.get_nodes_from_documents([Document(text=text)])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:05:42.280969Z","iopub.execute_input":"2024-03-13T18:05:42.281376Z","iopub.status.idle":"2024-03-13T18:05:42.288451Z","shell.execute_reply.started":"2024-03-13T18:05:42.281345Z","shell.execute_reply":"2024-03-13T18:05:42.287297Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print([x.text for x in nodes])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:05:42.516521Z","iopub.execute_input":"2024-03-13T18:05:42.516952Z","iopub.status.idle":"2024-03-13T18:05:42.523071Z","shell.execute_reply.started":"2024-03-13T18:05:42.516918Z","shell.execute_reply":"2024-03-13T18:05:42.521850Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"['hello. ', 'foo bar. ', 'cat dog. ', 'mouse']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(nodes[0].metadata[\"window\"])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:05:42.946991Z","iopub.execute_input":"2024-03-13T18:05:42.947373Z","iopub.status.idle":"2024-03-13T18:05:42.952940Z","shell.execute_reply.started":"2024-03-13T18:05:42.947347Z","shell.execute_reply":"2024-03-13T18:05:42.951686Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"hello.  foo bar.  cat dog.  mouse\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Building the index","metadata":{}},{"cell_type":"code","source":"\nllm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:08:00.070443Z","iopub.execute_input":"2024-03-13T18:08:00.070890Z","iopub.status.idle":"2024-03-13T18:08:00.076718Z","shell.execute_reply.started":"2024-03-13T18:08:00.070857Z","shell.execute_reply":"2024-03-13T18:08:00.075538Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"The service context container is a utility container for LlamaIndex index and query classes. The container contains the following objects that are commonly used for configuring every index and query, such as the LLM, the PromptHelper (for configuring input size/chunk size), the BaseEmbedding (for configuring the embedding model), and more.","metadata":{}},{"cell_type":"code","source":"sentence_context = ServiceContext.from_defaults(\n    llm=llm,\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    # embed_model=\"local:BAAI/bge-large-en-v1.5\"\n    node_parser=node_parser,\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:08:34.329257Z","iopub.execute_input":"2024-03-13T18:08:34.329646Z","iopub.status.idle":"2024-03-13T18:08:41.889595Z","shell.execute_reply.started":"2024-03-13T18:08:34.329618Z","shell.execute_reply":"2024-03-13T18:08:41.888399Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a33b04d60c48a8a3ffe86bbec5d169"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea0ea1dd3e5047c8bfce69dfa7504398"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"400205bbcff0461a92133516c4fc6ca7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a005483f1b1847cfbed68ee43474d150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd0df3dfb8d0424a99005b6ad33ab4e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ff27e0fa134b488771182cee3e3cfd"}},"metadata":{}}]},{"cell_type":"markdown","source":"Vector Stores are a key component of retrieval-augmented generation (RAG) and so you will end up using them in nearly every application you make using LlamaIndex, either directly or indirectly.\n\nVector stores accept a list of Node objects and build an index from them","metadata":{}},{"cell_type":"code","source":"sentence_index = VectorStoreIndex.from_documents(\n    [document], service_context=sentence_context\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:09:10.950678Z","iopub.execute_input":"2024-03-13T18:09:10.951403Z","iopub.status.idle":"2024-03-13T18:09:25.036333Z","shell.execute_reply.started":"2024-03-13T18:09:10.951368Z","shell.execute_reply":"2024-03-13T18:09:25.035125Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"sentence_index.storage_context.persist(persist_dir=\"./sentence_index\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:11:22.462192Z","iopub.execute_input":"2024-03-13T18:11:22.462625Z","iopub.status.idle":"2024-03-13T18:11:23.951723Z","shell.execute_reply.started":"2024-03-13T18:11:22.462592Z","shell.execute_reply":"2024-03-13T18:11:23.950717Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# This block of code is optional to check\n# if an index file exist, then it will load it\n# if not, it will rebuild it\n\nif not os.path.exists(\"./sentence_index\"):\n    sentence_index = VectorStoreIndex.from_documents(\n        [document], service_context=sentence_context\n    )\n\n    sentence_index.storage_context.persist(persist_dir=\"./sentence_index\")\nelse:\n    sentence_index = load_index_from_storage(\n        StorageContext.from_defaults(persist_dir=\"./sentence_index\"),\n        service_context=sentence_context\n    )","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:11:27.782838Z","iopub.execute_input":"2024-03-13T18:11:27.783240Z","iopub.status.idle":"2024-03-13T18:11:29.784517Z","shell.execute_reply.started":"2024-03-13T18:11:27.783208Z","shell.execute_reply":"2024-03-13T18:11:29.783246Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### Building the postprocessor","metadata":{}},{"cell_type":"markdown","source":"Used to replace the node content with a field from the node metadata. If the field is not present in the metadata, then the node text remains unchanged. Most useful when used in combination with the SentenceWindowNodeParser.","metadata":{}},{"cell_type":"code","source":"postproc = MetadataReplacementPostProcessor(\n    target_metadata_key=\"window\"\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:11:58.969513Z","iopub.execute_input":"2024-03-13T18:11:58.969918Z","iopub.status.idle":"2024-03-13T18:11:58.974892Z","shell.execute_reply.started":"2024-03-13T18:11:58.969888Z","shell.execute_reply":"2024-03-13T18:11:58.974103Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"scored_nodes = [NodeWithScore(node=x, score=1.0) for x in nodes]\nnodes_old = [deepcopy(n) for n in nodes]","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:12:00.779217Z","iopub.execute_input":"2024-03-13T18:12:00.779670Z","iopub.status.idle":"2024-03-13T18:12:00.788263Z","shell.execute_reply.started":"2024-03-13T18:12:00.779637Z","shell.execute_reply":"2024-03-13T18:12:00.786965Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"nodes_old[1].text","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:12:01.534691Z","iopub.execute_input":"2024-03-13T18:12:01.535088Z","iopub.status.idle":"2024-03-13T18:12:01.542851Z","shell.execute_reply.started":"2024-03-13T18:12:01.535060Z","shell.execute_reply":"2024-03-13T18:12:01.541617Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'foo bar. '"},"metadata":{}}]},{"cell_type":"code","source":"replaced_nodes = postproc.postprocess_nodes(scored_nodes)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:12:02.765526Z","iopub.execute_input":"2024-03-13T18:12:02.766145Z","iopub.status.idle":"2024-03-13T18:12:02.771142Z","shell.execute_reply.started":"2024-03-13T18:12:02.766117Z","shell.execute_reply":"2024-03-13T18:12:02.770049Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(replaced_nodes[1].text)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:12:03.648729Z","iopub.execute_input":"2024-03-13T18:12:03.649168Z","iopub.status.idle":"2024-03-13T18:12:03.655288Z","shell.execute_reply.started":"2024-03-13T18:12:03.649139Z","shell.execute_reply":"2024-03-13T18:12:03.654021Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"hello.  foo bar.  cat dog.  mouse\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Adding a reranker","metadata":{}},{"cell_type":"markdown","source":"Uses the cross-encoders from the sentence-transformer package to re-order nodes, and returns the top N nodes.","metadata":{}},{"cell_type":"code","source":"\n# BAAI/bge-reranker-base\n# link: https://huggingface.co/BAAI/bge-reranker-base\nrerank = SentenceTransformerRerank(\n    top_n=2, model=\"BAAI/bge-reranker-base\"\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:12:21.948451Z","iopub.execute_input":"2024-03-13T18:12:21.948895Z","iopub.status.idle":"2024-03-13T18:12:40.715611Z","shell.execute_reply.started":"2024-03-13T18:12:21.948844Z","shell.execute_reply":"2024-03-13T18:12:40.714741Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68dba2574220465fb4be4b423035fdf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6dc195ef0244cd29f0427a30b86e4b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b457394f67b04a1d90b93620e15df6c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4408232a72544e5ac1189b6614a5292"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"534a8017c959472187eae6b0873d3cad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a185bf01a0442f5b9b3d7cd22093867"}},"metadata":{}}]},{"cell_type":"code","source":"query = QueryBundle(\"I want a dog.\")\n\nscored_nodes = [\n    NodeWithScore(node=TextNode(text=\"This is a cat\"), score=0.6),\n    NodeWithScore(node=TextNode(text=\"This is a dog\"), score=0.4),\n]","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:12:40.901712Z","iopub.execute_input":"2024-03-13T18:12:40.902157Z","iopub.status.idle":"2024-03-13T18:12:40.908539Z","shell.execute_reply.started":"2024-03-13T18:12:40.902125Z","shell.execute_reply":"2024-03-13T18:12:40.907147Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"reranked_nodes = rerank.postprocess_nodes(\n    scored_nodes, query_bundle=query\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:12:43.245865Z","iopub.execute_input":"2024-03-13T18:12:43.246289Z","iopub.status.idle":"2024-03-13T18:12:43.382132Z","shell.execute_reply.started":"2024-03-13T18:12:43.246256Z","shell.execute_reply":"2024-03-13T18:12:43.380890Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"920edabd6f344971a1aaaec10d9b0507"}},"metadata":{}}]},{"cell_type":"code","source":"print([(x.text, x.score) for x in reranked_nodes])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:12:46.206575Z","iopub.execute_input":"2024-03-13T18:12:46.207060Z","iopub.status.idle":"2024-03-13T18:12:46.212582Z","shell.execute_reply.started":"2024-03-13T18:12:46.207024Z","shell.execute_reply":"2024-03-13T18:12:46.211743Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"[('This is a dog', 0.9182736), ('This is a cat', 0.0014040766)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Runing the query engine","metadata":{}},{"cell_type":"code","source":"sentence_window_engine = sentence_index.as_query_engine(\n    similarity_top_k=6, node_postprocessors=[postproc, rerank]\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:12:58.402972Z","iopub.execute_input":"2024-03-13T18:12:58.404236Z","iopub.status.idle":"2024-03-13T18:12:58.409371Z","shell.execute_reply.started":"2024-03-13T18:12:58.404193Z","shell.execute_reply":"2024-03-13T18:12:58.408118Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"window_response = sentence_window_engine.query(\n    \"What are the keys to building a career in AI?\"\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T18:13:02.788633Z","iopub.execute_input":"2024-03-13T18:13:02.789072Z","iopub.status.idle":"2024-03-13T18:13:07.298887Z","shell.execute_reply.started":"2024-03-13T18:13:02.789039Z","shell.execute_reply":"2024-03-13T18:13:07.297751Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8576e32f75c2449a9c2bd86f43f8e502"}},"metadata":{}}]},{"cell_type":"code","source":"display_response(window_response)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:13:08.447259Z","iopub.execute_input":"2024-03-13T18:13:08.447642Z","iopub.status.idle":"2024-03-13T18:13:08.455496Z","shell.execute_reply.started":"2024-03-13T18:13:08.447615Z","shell.execute_reply":"2024-03-13T18:13:08.454396Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**`Final Response:`** The keys to building a career in AI involve learning foundational technical skills, working on projects, finding a job, and being part of a supportive community."},"metadata":{}}]},{"cell_type":"markdown","source":"## Putting it all Together","metadata":{}},{"cell_type":"code","source":"def build_sentence_window_index(\n    documents,\n    llm,\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    sentence_window_size=3,\n    save_dir=\"sentence_index\",\n):\n    # create the sentence window node parser w/ default settings\n    node_parser = SentenceWindowNodeParser.from_defaults(\n        window_size=sentence_window_size,\n        window_metadata_key=\"window\",\n        original_text_metadata_key=\"original_text\",\n    )\n    sentence_context = ServiceContext.from_defaults(\n        llm=llm,\n        embed_model=embed_model,\n        node_parser=node_parser,\n    )\n    if not os.path.exists(save_dir):\n        sentence_index = VectorStoreIndex.from_documents(\n            documents, service_context=sentence_context\n        )\n        sentence_index.storage_context.persist(persist_dir=save_dir)\n    else:\n        sentence_index = load_index_from_storage(\n            StorageContext.from_defaults(persist_dir=save_dir),\n            service_context=sentence_context,\n        )\n\n    return sentence_index\n\n\ndef get_sentence_window_query_engine(\n    sentence_index, similarity_top_k=6, rerank_top_n=2\n):\n    # define postprocessors\n    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n    rerank = SentenceTransformerRerank(\n        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n    )\n\n    sentence_window_engine = sentence_index.as_query_engine(\n        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n    )\n    return sentence_window_engine","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:13:22.004717Z","iopub.execute_input":"2024-03-13T18:13:22.005185Z","iopub.status.idle":"2024-03-13T18:13:22.016736Z","shell.execute_reply.started":"2024-03-13T18:13:22.005153Z","shell.execute_reply":"2024-03-13T18:13:22.015773Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"index = build_sentence_window_index(\n    [document],\n    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n    save_dir=\"./sentence_index\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:13:23.614759Z","iopub.execute_input":"2024-03-13T18:13:23.615201Z","iopub.status.idle":"2024-03-13T18:13:26.622677Z","shell.execute_reply.started":"2024-03-13T18:13:23.615169Z","shell.execute_reply":"2024-03-13T18:13:26.621504Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"query_engine = get_sentence_window_query_engine(index, similarity_top_k=6)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:13:29.102807Z","iopub.execute_input":"2024-03-13T18:13:29.103966Z","iopub.status.idle":"2024-03-13T18:13:32.325722Z","shell.execute_reply.started":"2024-03-13T18:13:29.103929Z","shell.execute_reply":"2024-03-13T18:13:32.324505Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## TruLens Evaluation","metadata":{}},{"cell_type":"code","source":"eval_questions = []\nwith open('/kaggle/input/data-test/generated_questions.text', 'r') as file:\n    for line in file:\n        # Remove newline character and convert to integer\n        item = line.strip()\n        eval_questions.append(item)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:13:36.447362Z","iopub.execute_input":"2024-03-13T18:13:36.448063Z","iopub.status.idle":"2024-03-13T18:13:36.461088Z","shell.execute_reply.started":"2024-03-13T18:13:36.448029Z","shell.execute_reply":"2024-03-13T18:13:36.459889Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from trulens_eval import Tru\n\ndef run_evals(eval_questions, tru_recorder, query_engine):\n    for question in eval_questions:\n        with tru_recorder as recording:\n            response = query_engine.query(question)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:13:38.365048Z","iopub.execute_input":"2024-03-13T18:13:38.365425Z","iopub.status.idle":"2024-03-13T18:13:38.371878Z","shell.execute_reply.started":"2024-03-13T18:13:38.365397Z","shell.execute_reply":"2024-03-13T18:13:38.370680Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from trulens_eval import Tru\n\nTru().reset_database()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:13:41.335036Z","iopub.execute_input":"2024-03-13T18:13:41.335413Z","iopub.status.idle":"2024-03-13T18:13:41.455216Z","shell.execute_reply.started":"2024-03-13T18:13:41.335386Z","shell.execute_reply":"2024-03-13T18:13:41.454162Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\nðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Sentence window size = 1","metadata":{}},{"cell_type":"code","source":"sentence_index_1 = build_sentence_window_index(\n    documents,\n    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    sentence_window_size=1,\n    save_dir=\"sentence_index_1\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:13:57.487096Z","iopub.execute_input":"2024-03-13T18:13:57.487499Z","iopub.status.idle":"2024-03-13T18:14:19.692137Z","shell.execute_reply.started":"2024-03-13T18:13:57.487470Z","shell.execute_reply":"2024-03-13T18:14:19.690877Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"sentence_window_engine_1 = get_sentence_window_query_engine(\n    sentence_index_1\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:14:19.693848Z","iopub.execute_input":"2024-03-13T18:14:19.695004Z","iopub.status.idle":"2024-03-13T18:14:22.274574Z","shell.execute_reply.started":"2024-03-13T18:14:19.694970Z","shell.execute_reply":"2024-03-13T18:14:22.273396Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"tru_recorder_1 = get_prebuilt_trulens_recorder(\n    sentence_window_engine_1,\n    app_id='sentence window engine 1'\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:18:16.986704Z","iopub.execute_input":"2024-03-13T18:18:16.987138Z","iopub.status.idle":"2024-03-13T18:18:17.795470Z","shell.execute_reply.started":"2024-03-13T18:18:16.987108Z","shell.execute_reply":"2024-03-13T18:18:17.794517Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\nâœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\nâœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\nâœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\nâœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\nâœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n","output_type":"stream"}]},{"cell_type":"code","source":"run_evals(eval_questions, tru_recorder_1, sentence_window_engine_1)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:18:28.138970Z","iopub.execute_input":"2024-03-13T18:18:28.139352Z","iopub.status.idle":"2024-03-13T18:18:43.463444Z","shell.execute_reply.started":"2024-03-13T18:18:28.139324Z","shell.execute_reply":"2024-03-13T18:18:43.451234Z"},"trusted":true},"execution_count":63,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ddc3b44f7b40179e79ebf6f2df71d0"}},"metadata":{}}]},{"cell_type":"code","source":"Tru().run_dashboard()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:18:43.476114Z","iopub.execute_input":"2024-03-13T18:18:43.482763Z","iopub.status.idle":"2024-03-13T18:18:45.058528Z","shell.execute_reply.started":"2024-03-13T18:18:43.482718Z","shell.execute_reply":"2024-03-13T18:18:45.057715Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Starting dashboard ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f5483c911394f2792b0e6c70581a2ff"}},"metadata":{}},{"name":"stdout","text":"Dashboard started at http://172.19.2.2:8501 .\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Note about the dataset of questions\n- Since this evaluation process takes a long time to run, the following file `generated_questions.text` contains one question (the one mentioned in the lecture video).\n- If you would like to explore other possible questions, feel free to explore the file directory by clicking on the \"Jupyter\" logo at the top right of this notebook. You'll see the following `.text` files:\n\n> - `generated_questions_01_05.text`\n> - `generated_questions_06_10.text`\n> - `generated_questions_11_15.text`\n> - `generated_questions_16_20.text`\n> - `generated_questions_21_24.text`\n\nNote that running an evaluation on more than one question can take some time, so we recommend choosing one of these files (with 5 questions each) to run and explore the results.\n\n- For evaluating a personal project, an eval set of 20 is reasonable.\n- For evaluating business applications, you may need a set of 100+ in order to cover all the use cases thoroughly.\n- Note that since API calls can sometimes fail, you may occasionally see null responses, and would want to re-run your evaluations.  So running your evaluations in smaller batches can also help you save time and cost by only re-running the evaluation on the batches with issues.","metadata":{}},{"cell_type":"code","source":"eval_questions = []\nwith open('/kaggle/input/data-test/generated_questions.text', 'r') as file:\n    for line in file:\n        # Remove newline character and convert to integer\n        item = line.strip()\n        eval_questions.append(item)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:19:56.515505Z","iopub.execute_input":"2024-03-13T18:19:56.515976Z","iopub.status.idle":"2024-03-13T18:19:56.525245Z","shell.execute_reply.started":"2024-03-13T18:19:56.515941Z","shell.execute_reply":"2024-03-13T18:19:56.523882Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"### Sentence window size = 3","metadata":{}},{"cell_type":"code","source":"sentence_index_3 = build_sentence_window_index(\n    documents,\n    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    sentence_window_size=3,\n    save_dir=\"sentence_index_3\",\n)\nsentence_window_engine_3 = get_sentence_window_query_engine(\n    sentence_index_3\n)\n\ntru_recorder_3 = get_prebuilt_trulens_recorder(\n    sentence_window_engine_3,\n    app_id='sentence window engine 3'\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:20:00.794653Z","iopub.execute_input":"2024-03-13T18:20:00.795057Z","iopub.status.idle":"2024-03-13T18:20:26.296762Z","shell.execute_reply.started":"2024-03-13T18:20:00.795023Z","shell.execute_reply":"2024-03-13T18:20:26.295682Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\nâœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\nâœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\nâœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\nâœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\nâœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n","output_type":"stream"}]},{"cell_type":"code","source":"run_evals(eval_questions, tru_recorder_3, sentence_window_engine_3)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:20:26.298820Z","iopub.execute_input":"2024-03-13T18:20:26.299165Z","iopub.status.idle":"2024-03-13T18:20:39.184588Z","shell.execute_reply.started":"2024-03-13T18:20:26.299136Z","shell.execute_reply":"2024-03-13T18:20:39.183137Z"},"trusted":true},"execution_count":67,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d4981c2de9940d48b55c424b96d4de4"}},"metadata":{}}]},{"cell_type":"code","source":"Tru().run_dashboard()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:20:39.192625Z","iopub.execute_input":"2024-03-13T18:20:39.193046Z","iopub.status.idle":"2024-03-13T18:20:39.250906Z","shell.execute_reply.started":"2024-03-13T18:20:39.193009Z","shell.execute_reply":"2024-03-13T18:20:39.249702Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Starting dashboard ...\nConfig file already exists. Skipping writing process.\nCredentials file already exists. Skipping writing process.\nDashboard already running at path:   Network URL: http://172.19.2.2:8501\n\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}